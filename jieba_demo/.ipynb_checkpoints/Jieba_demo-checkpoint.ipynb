{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jieba分词Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jieba分词github：https://github.com/fxsjy/jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、jieba分词原理\n",
    "#### 1.1 基于规则是指根据一个已有的词典，采用前向最大匹配、后向最大匹配、双向最大匹配等人工设定的规则来进行分词。例如对于 “上海自来水来自海上” 这句话，使用前向最大匹配，即从前向后扫描，使分出来的词存在于词典中并且尽可能长，则可以得到 “上海 / 自来水 / 来自 / 海上”。\n",
    "#### 1.2 基于统计是从大量人工标注语料中总结词的概率分布以及词之间的常用搭配，使用有监督学习训练分词模型。对于 “上海自来水来自海上” 这句话，一个最简单的统计分词想法是，尝试所有可能的分词方案，因为任何两个字之间，要么需要切分，要么无需切分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、jieba安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python2下\n",
    "```\n",
    "pip install jieba\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python3下\n",
    "```\n",
    "pip3 install jieba\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、jieba使用demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/_2/6z88r20s6xz6nh2npj1wm14c0000gn/T/jieba.cache\n",
      "Loading model cost 1.436 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#数据读入\n",
    "data = pd.read_csv('pointtag.csv')\n",
    "jieba.load_userdict(\"fool_dic\")\n",
    "#加载停用词表\n",
    "def stopwordslist(filepath):  \n",
    "    stopwords = [line.strip() for line in open(filepath, 'r').readlines()]  \n",
    "    return stopwords  \n",
    "#对知识点短语分词\n",
    "#IO 时间损耗，每次运行程序都会读入停用词表\n",
    "def seg_keypoint(sentence):  \n",
    "    sentence_seged = jieba.cut(sentence.strip())  \n",
    "    stopwords = stopwordslist('stopwords.txt')  # 这里加载停用词的路径  \n",
    "    outstr = ''  \n",
    "    for word in sentence_seged:  \n",
    "        if word not in stopwords:  \n",
    "            if word != '\\t':  \n",
    "                outstr += word  \n",
    "                outstr += \" \"  \n",
    "    return outstr  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seg_sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ef498035f344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'知识点'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seg_sentence' is not defined"
     ]
    }
   ],
   "source": [
    "#选取pointtag.csv中1000条数据进行测试\n",
    "result = list()\n",
    "for keyword in data['知识点'][0:1000]:\n",
    "    tag = seg_sentence(keyword)\n",
    "    result.append(tag.strip())\n",
    "result = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
